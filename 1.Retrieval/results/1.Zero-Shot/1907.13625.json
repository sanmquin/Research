{
  "references": {
    "seed": {
      "arxivId": "2509.25140",
      "title": "ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory"
    },
    "sources": [
      {
        "arxivId": "2509.03646",
        "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning"
      },
      {
        "arxivId": "2508.12031",
        "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases"
      },
      {
        "arxivId": "2508.06433",
        "title": "Memp: Exploring Agent Procedural Memory"
      },
      {
        "arxivId": "2508.04700",
        "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience"
      },
      {
        "arxivId": "2507.21953",
        "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation"
      },
      {
        "arxivId": "2507.21428",
        "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations"
      },
      {
        "arxivId": "2507.21046",
        "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence"
      },
      {
        "arxivId": "2507.06229",
        "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving"
      },
      {
        "arxivId": "2507.06261",
        "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities"
      },
      {
        "arxivId": "2507.05257",
        "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions"
      },
      {
        "arxivId": "2507.04607",
        "title": "PRIME: Large Language Model Personalization with Cognitive Dual-Memory and Personalized Thought Process"
      },
      {
        "arxivId": "2507.02259",
        "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent"
      },
      {
        "arxivId": "2506.15841",
        "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents"
      },
      {
        "arxivId": "2506.12928",
        "title": "Scaling Test-time Compute for LLM Agents"
      },
      {
        "arxivId": "2506.07976",
        "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction"
      },
      {
        "arxivId": "2506.06698",
        "title": "Contextual Experience Replay for Self-Improvement of Language Agents"
      },
      {
        "arxivId": "2506.01952",
        "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks"
      },
      {
        "arxivId": "2505.22101",
        "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models"
      },
      {
        "arxivId": "2504.20595",
        "title": "ReasonIR: Training Retrievers for Reasoning Tasks"
      },
      {
        "arxivId": "2504.19413",
        "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory"
      },
      {
        "arxivId": "2504.13837",
        "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?"
      },
      {
        "arxivId": "2504.09772",
        "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning"
      },
      {
        "arxivId": "2504.06821",
        "title": "Inducing Programmatic Skills for Agentic Tasks"
      },
      {
        "arxivId": "2504.00810",
        "title": "Z1: Efficient Test-time Scaling with Code"
      },
      {
        "arxivId": "2504.01990",
        "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems"
      },
      {
        "arxivId": "2503.08026",
        "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents"
      },
      {
        "arxivId": "2503.07891",
        "title": "Gemini Embedding: Generalizable Embeddings from Gemini"
      },
      {
        "arxivId": "2502.14382",
        "title": "S*: Test Time Scaling for Code Generation"
      },
      {
        "arxivId": "2502.12110",
        "title": "A-MEM: Agentic Memory for LLM Agents"
      },
      {
        "arxivId": "2502.12118",
        "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal"
      },
      {
        "arxivId": "2502.00592",
        "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory"
      },
      {
        "arxivId": "2501.19393",
        "title": "s1: Simple test-time scaling"
      },
      {
        "arxivId": "2501.10893",
        "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments"
      },
      {
        "arxivId": "2412.15287",
        "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models"
      },
      {
        "arxivId": "2412.05467",
        "title": "The BrowserGym Ecosystem for Web Agent Research"
      },
      {
        "arxivId": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge"
      },
      {
        "arxivId": "2410.10813",
        "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory"
      },
      {
        "arxivId": "2410.02052",
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning"
      },
      {
        "arxivId": "2409.07429",
        "title": "Agent Workflow Memory"
      },
      {
        "arxivId": "2409.00872",
        "title": "Self-evolving Agents with reflective and memory-augmented abilities"
      },
      {
        "arxivId": "2408.09559",
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model"
      },
      {
        "arxivId": "2407.09450",
        "title": "Human-inspired Episodic Memory for Infinite Context LLMs"
      },
      {
        "arxivId": "2406.08747",
        "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents"
      },
      {
        "arxivId": "2405.15793",
        "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering"
      },
      {
        "arxivId": "2404.13501",
        "title": "A Survey on the Memory Mechanism of Large Language Model-based Agents"
      },
      {
        "arxivId": "2404.07972",
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments"
      },
      {
        "arxivId": "2404.06474",
        "title": "Autonomous Evaluation and Refinement of Digital Agents"
      },
      {
        "arxivId": "2402.17753",
        "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents"
      },
      {
        "arxivId": "2402.05403",
        "title": "In-Context Principle Learning from Mistakes"
      },
      {
        "arxivId": "2402.03610",
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents"
      },
      {
        "arxivId": "2401.13996",
        "title": "Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution"
      },
      {
        "arxivId": "2310.08560",
        "title": "MemGPT: Towards LLMs as Operating Systems"
      },
      {
        "arxivId": "2308.11432",
        "title": "A Survey on Large Language Model based Autonomous Agents"
      },
      {
        "arxivId": "2308.10144",
        "title": "ExpeL: LLM Agents Are Experiential Learners"
      },
      {
        "arxivId": "2307.13854",
        "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents"
      },
      {
        "arxivId": "2307.12856",
        "title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"
      },
      {
        "arxivId": "2306.07863",
        "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control"
      },
      {
        "arxivId": "2306.06070",
        "title": "Mind2Web: Towards a Generalist Agent for the Web"
      },
      {
        "arxivId": "2305.10250",
        "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory"
      },
      {
        "arxivId": "2303.17651",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      },
      {
        "arxivId": "2210.03629",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models"
      },
      {
        "arxivId": "2002.05709",
        "title": "A Simple Framework for Contrastive Learning of Visual Representations"
      }
    ],
    "selectedSource": {
      "arxivId": "2002.05709",
      "title": "A Simple Framework for Contrastive Learning of Visual Representations"
    },
    "target": {
      "arxivId": "1907.13625",
      "title": "On Mutual Information Maximization for Representation Learning"
    }
  },
  "embeddings": {
    "rank": 1,
    "ordered": [
      {
        "arxivId": "2002.05709",
        "title": "A Simple Framework for Contrastive Learning of Visual Representations",
        "distance": 0.4544906280361044
      },
      {
        "arxivId": "2503.07891",
        "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
        "distance": 0.5659992554571185
      },
      {
        "arxivId": "2508.12031",
        "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases",
        "distance": 0.59914451332527
      },
      {
        "arxivId": "2506.15841",
        "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
        "distance": 0.6048834210807745
      },
      {
        "arxivId": "2504.20595",
        "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
        "distance": 0.6177759911811302
      },
      {
        "arxivId": "2402.03610",
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
        "distance": 0.6188234793530352
      },
      {
        "arxivId": "2504.09772",
        "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
        "distance": 0.6197767286635161
      },
      {
        "arxivId": "2505.22101",
        "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models",
        "distance": 0.6312914125776794
      },
      {
        "arxivId": "2410.02052",
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
        "distance": 0.6318088885241239
      },
      {
        "arxivId": "2502.12110",
        "title": "A-MEM: Agentic Memory for LLM Agents",
        "distance": 0.6324636393068631
      },
      {
        "arxivId": "2305.10250",
        "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
        "distance": 0.6336252250240755
      },
      {
        "arxivId": "2404.13501",
        "title": "A Survey on the Memory Mechanism of Large Language Model-based Agents",
        "distance": 0.6361544126272047
      },
      {
        "arxivId": "2402.05403",
        "title": "In-Context Principle Learning from Mistakes",
        "distance": 0.6398333701569813
      },
      {
        "arxivId": "2409.00872",
        "title": "Self-evolving Agents with reflective and memory-augmented abilities",
        "distance": 0.6418121562180819
      },
      {
        "arxivId": "2412.15287",
        "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models",
        "distance": 0.6441661714461773
      },
      {
        "arxivId": "2507.21046",
        "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence",
        "distance": 0.6453900607843963
      },
      {
        "arxivId": "2402.17753",
        "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
        "distance": 0.6457607830681424
      },
      {
        "arxivId": "2507.05257",
        "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions",
        "distance": 0.6494886681134637
      },
      {
        "arxivId": "2507.06229",
        "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
        "distance": 0.6496690553857047
      },
      {
        "arxivId": "2504.06821",
        "title": "Inducing Programmatic Skills for Agentic Tasks",
        "distance": 0.6502101487851122
      },
      {
        "arxivId": "2507.02259",
        "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
        "distance": 0.6515112192337946
      },
      {
        "arxivId": "2504.19413",
        "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
        "distance": 0.6567593764383345
      },
      {
        "arxivId": "2508.06433",
        "title": "Memp: Exploring Agent Procedural Memory",
        "distance": 0.6569748578832602
      },
      {
        "arxivId": "2501.10893",
        "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
        "distance": 0.656990117871201
      },
      {
        "arxivId": "2401.13996",
        "title": "Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution",
        "distance": 0.6614571010466439
      },
      {
        "arxivId": "2407.09450",
        "title": "Human-inspired Episodic Memory for Infinite Context LLMs",
        "distance": 0.661691163070441
      },
      {
        "arxivId": "2303.17651",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback",
        "distance": 0.6617748180433374
      },
      {
        "arxivId": "2308.11432",
        "title": "A Survey on Large Language Model based Autonomous Agents",
        "distance": 0.6626968595422441
      },
      {
        "arxivId": "2503.08026",
        "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents",
        "distance": 0.6632499122534616
      },
      {
        "arxivId": "2507.06261",
        "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
        "distance": 0.6639915637084821
      },
      {
        "arxivId": "2508.04700",
        "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
        "distance": 0.6647854530236694
      },
      {
        "arxivId": "2507.04607",
        "title": "PRIME: Large Language Model Personalization with Cognitive Dual-Memory and Personalized Thought Process",
        "distance": 0.6698680321758173
      },
      {
        "arxivId": "2502.00592",
        "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory",
        "distance": 0.6701834231091894
      },
      {
        "arxivId": "2306.06070",
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "distance": 0.6713395304433195
      },
      {
        "arxivId": "2506.06698",
        "title": "Contextual Experience Replay for Self-Improvement of Language Agents",
        "distance": 0.6714099726162412
      },
      {
        "arxivId": "2404.07972",
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "distance": 0.6730539499808396
      },
      {
        "arxivId": "2404.06474",
        "title": "Autonomous Evaluation and Refinement of Digital Agents",
        "distance": 0.6744782745670832
      },
      {
        "arxivId": "2504.01990",
        "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
        "distance": 0.6763746125922968
      },
      {
        "arxivId": "2306.07863",
        "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
        "distance": 0.6816631767884636
      },
      {
        "arxivId": "2507.21428",
        "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations",
        "distance": 0.6855827621228326
      },
      {
        "arxivId": "2410.10813",
        "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory",
        "distance": 0.6867190073862057
      },
      {
        "arxivId": "2509.03646",
        "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning",
        "distance": 0.6869585426157578
      },
      {
        "arxivId": "2406.08747",
        "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents",
        "distance": 0.6874873001068331
      },
      {
        "arxivId": "2504.13837",
        "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
        "distance": 0.6915230619448591
      },
      {
        "arxivId": "2307.12856",
        "title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
        "distance": 0.7051350918866035
      },
      {
        "arxivId": "2408.09559",
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
        "distance": 0.7054652539879177
      },
      {
        "arxivId": "2507.21953",
        "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation",
        "distance": 0.7071460953408244
      },
      {
        "arxivId": "2506.12928",
        "title": "Scaling Test-time Compute for LLM Agents",
        "distance": 0.7074171839861403
      },
      {
        "arxivId": "2210.03629",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
        "distance": 0.7104381046108332
      },
      {
        "arxivId": "2307.13854",
        "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
        "distance": 0.7227857733502404
      },
      {
        "arxivId": "2412.05467",
        "title": "The BrowserGym Ecosystem for Web Agent Research",
        "distance": 0.7278144851200117
      },
      {
        "arxivId": "2308.10144",
        "title": "ExpeL: LLM Agents Are Experiential Learners",
        "distance": 0.7294366443047178
      },
      {
        "arxivId": "2506.07976",
        "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
        "distance": 0.731692320361421
      },
      {
        "arxivId": "2502.14382",
        "title": "S*: Test Time Scaling for Code Generation",
        "distance": 0.737676954330106
      },
      {
        "arxivId": "2501.19393",
        "title": "s1: Simple test-time scaling",
        "distance": 0.7386242697454117
      },
      {
        "arxivId": "2405.15793",
        "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
        "distance": 0.7425673263365647
      },
      {
        "arxivId": "2310.08560",
        "title": "MemGPT: Towards LLMs as Operating Systems",
        "distance": 0.7439437340354329
      },
      {
        "arxivId": "2502.12118",
        "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
        "distance": 0.7462283838865902
      },
      {
        "arxivId": "2506.01952",
        "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
        "distance": 0.7530750508957954
      },
      {
        "arxivId": "2504.00810",
        "title": "Z1: Efficient Test-time Scaling with Code",
        "distance": 0.7757896464328289
      },
      {
        "arxivId": "2409.07429",
        "title": "Agent Workflow Memory",
        "distance": 0.7812057997475375
      },
      {
        "arxivId": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge",
        "distance": 0.802781271219826
      }
    ]
  },
  "llm": {
    "rank": 7,
    "ordered": [
      {
        "index": 1,
        "arxivId": "2509.03646",
        "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning",
        "score": 8,
        "reason": "Both papers discuss reasoning in LLMs, with this one focusing on emergent hierarchical reasoning which could build upon or be compared to the target's representation learning approach."
      },
      {
        "index": 2,
        "arxivId": "2508.12031",
        "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases",
        "score": 7,
        "reason": "This paper focuses on continual learning and learning from errors, which can be related to how representation learning might adapt or improve over time, similar to the target paper's focus."
      },
      {
        "index": 3,
        "arxivId": "2504.19413",
        "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
        "score": 7,
        "reason": "The target paper is about representation learning, and this paper discusses memory which is a key component in learning and representation. Scalable long-term memory could be informed by better representations."
      },
      {
        "index": 4,
        "arxivId": "2504.20595",
        "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
        "score": 6,
        "reason": "This paper is about training retrievers for reasoning tasks. Representation learning is foundational for effective retrieval and reasoning."
      },
      {
        "index": 5,
        "arxivId": "2503.07891",
        "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
        "score": 6,
        "reason": "The target paper is about representation learning, and embeddings are a direct output of representation learning. This paper's focus on generalizable embeddings is highly relevant."
      },
      {
        "index": 6,
        "arxivId": "2404.13501",
        "title": "A Survey on the Memory Mechanism of Large Language Model-based Agents",
        "score": 6,
        "reason": "This survey covers memory mechanisms in LLM agents. Representation learning is crucial for effective memory systems, making this a relevant background or comparative study."
      },
      {
        "index": 7,
        "arxivId": "2002.05709",
        "title": "A Simple Framework for Contrastive Learning of Visual Representations",
        "score": 5,
        "reason": "Although focused on visual representations, this paper is a foundational work in contrastive learning, a method often used in representation learning, making it a relevant methodological precursor."
      },
      {
        "index": 8,
        "arxivId": "2506.01952",
        "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
        "score": 5,
        "reason": "This paper evaluates agents on web tasks. Improved representations could enhance agent performance in such environments."
      },
      {
        "index": 9,
        "arxivId": "2504.00810",
        "title": "Z1: Efficient Test-time Scaling with Code",
        "score": 5,
        "reason": "Test-time scaling involves adapting models, which relies on efficient representations and learning mechanisms. This could be an application area for improved representation learning."
      },
      {
        "index": 10,
        "arxivId": "2405.15793",
        "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
        "score": 5,
        "reason": "Software engineering agents require understanding and generating code, tasks that benefit greatly from robust representation learning."
      },
      {
        "index": 11,
        "arxivId": "2507.21953",
        "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation",
        "score": 4,
        "reason": "Memory-augmented systems require effective representations to store and retrieve information, making this indirectly related to representation learning."
      },
      {
        "index": 12,
        "arxivId": "2507.06229",
        "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
        "score": 4,
        "reason": "Knowledge bases are built upon representations of information. Leveraging cross-domain experience implies learning generalized representations."
      },
      {
        "index": 13,
        "arxivId": "2507.05257",
        "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions",
        "score": 4,
        "reason": "Evaluating memory requires understanding how information is represented and retained. This connects to the target's focus on representation learning."
      },
      {
        "index": 14,
        "arxivId": "2507.02259",
        "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
        "score": 4,
        "reason": "Memory agents rely on effective representations to handle long contexts. This paper's focus on memory could intersect with representation learning techniques."
      },
      {
        "index": 15,
        "arxivId": "2506.15841",
        "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
        "score": 4,
        "reason": "This paper focuses on memory and reasoning for agents. Effective representations are key to both of these components."
      },
      {
        "index": 16,
        "arxivId": "2506.06698",
        "title": "Contextual Experience Replay for Self-Improvement of Language Agents",
        "score": 4,
        "reason": "Experience replay is a learning mechanism that benefits from well-represented experiences. This could be an area where representation learning is applied."
      },
      {
        "index": 17,
        "arxivId": "2504.09772",
        "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
        "score": 4,
        "reason": "Multi-agent collaboration and reasoning can be improved by shared or complementary representations."
      },
      {
        "index": 18,
        "arxivId": "2504.06821",
        "title": "Inducing Programmatic Skills for Agentic Tasks",
        "score": 4,
        "reason": "Learning programmatic skills likely involves learning representations of code and task structures."
      },
      {
        "index": 19,
        "arxivId": "2503.08026",
        "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents",
        "score": 4,
        "reason": "Memory management in dialogue agents is directly tied to how information is represented and processed over time."
      },
      {
        "index": 20,
        "arxivId": "2502.12110",
        "title": "A-MEM: Agentic Memory for LLM Agents",
        "score": 4,
        "reason": "Agentic memory is fundamentally about how information is stored and retrieved, which relies on effective representations."
      },
      {
        "index": 21,
        "arxivId": "2502.00592",
        "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory",
        "score": 4,
        "reason": "Extending long-term memory necessitates better ways to represent and store information, linking to the target's research."
      },
      {
        "index": 22,
        "arxivId": "2501.10893",
        "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
        "score": 4,
        "reason": "Learning from interaction can lead to better representations of the environment and task dynamics."
      },
      {
        "index": 23,
        "arxivId": "2410.10813",
        "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory",
        "score": 4,
        "reason": "Benchmarking long-term memory implicitly evaluates the underlying representation mechanisms."
      },
      {
        "index": 24,
        "arxivId": "2409.07429",
        "title": "Agent Workflow Memory",
        "score": 4,
        "reason": "Workflow memory in agents depends on how steps and states are represented and managed."
      },
      {
        "index": 25,
        "arxivId": "2409.00872",
        "title": "Self-evolving Agents with reflective and memory-augmented abilities",
        "score": 4,
        "reason": "Self-evolving agents benefit from robust memory and reflective capabilities, which are underpinned by effective representation learning."
      },
      {
        "index": 26,
        "arxivId": "2408.09559",
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
        "score": 4,
        "reason": "Hierarchical memory management implies structured representations are learned or utilized."
      },
      {
        "index": 27,
        "arxivId": "2407.09450",
        "title": "Human-inspired Episodic Memory for Infinite Context LLMs",
        "score": 4,
        "reason": "Episodic memory relies on detailed representations of past events. This is a direct link to representation learning."
      },
      {
        "index": 28,
        "arxivId": "2404.07972",
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "score": 4,
        "reason": "Multimodal agents need to learn representations across different modalities, a complex form of representation learning."
      },
      {
        "index": 29,
        "arxivId": "2402.05403",
        "title": "In-Context Principle Learning from Mistakes",
        "score": 4,
        "reason": "Learning principles from mistakes involves forming representations of correct and incorrect patterns."
      },
      {
        "index": 30,
        "arxivId": "2402.03610",
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
        "score": 4,
        "reason": "Retrieval-augmented systems and multimodal agents rely heavily on effective representations for planning and context understanding."
      },
      {
        "index": 31,
        "arxivId": "2310.08560",
        "title": "MemGPT: Towards LLMs as Operating Systems",
        "score": 4,
        "reason": "Treating LLMs as operating systems implies managing complex internal states and memory, which requires advanced representation learning."
      },
      {
        "index": 32,
        "arxivId": "2308.10144",
        "title": "ExpeL: LLM Agents Are Experiential Learners",
        "score": 4,
        "reason": "Experiential learning in agents aims to build knowledge and understanding, which is achieved through representation learning."
      },
      {
        "index": 33,
        "arxivId": "2306.07863",
        "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
        "score": 4,
        "reason": "Computer control via memory requires learning effective representations of trajectories and states."
      },
      {
        "index": 34,
        "arxivId": "2305.10250",
        "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
        "score": 4,
        "reason": "Long-term memory enhancement in LLMs relies on learning and utilizing effective representations of past information."
      },
      {
        "index": 35,
        "arxivId": "2210.03629",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
        "score": 3,
        "reason": "ReAct combines reasoning and acting, which benefits from strong internal representations of the task and environment."
      },
      {
        "index": 36,
        "arxivId": "2508.04700",
        "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
        "score": 3,
        "reason": "Self-evolving agents learn from experience, implying the formation of representations to guide future actions."
      },
      {
        "index": 37,
        "arxivId": "2507.21428",
        "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations",
        "score": 3,
        "reason": "Memory management for tool calling involves representing tool capabilities and conversation states, which relates to representation learning."
      },
      {
        "index": 38,
        "arxivId": "2507.06261",
        "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
        "score": 3,
        "reason": "Advanced reasoning and long context capabilities often rely on sophisticated representation learning techniques."
      },
      {
        "index": 39,
        "arxivId": "2506.12928",
        "title": "Scaling Test-time Compute for LLM Agents",
        "score": 3,
        "reason": "Efficient computation at test-time can be achieved through optimized representations."
      },
      {
        "index": 40,
        "arxivId": "2506.07976",
        "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
        "score": 3,
        "reason": "Reasoning through test-time interaction implies learning from these interactions, which requires representation of the learned information."
      },
      {
        "index": 41,
        "arxivId": "2505.22101",
        "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models",
        "score": 3,
        "reason": "An OS for memory-augmented generation suggests sophisticated memory management and state representation."
      },
      {
        "index": 42,
        "arxivId": "2504.13837",
        "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
        "score": 3,
        "reason": "This paper questions the impact of RL on reasoning. Representation learning is a component that could enable or enhance reasoning capacity."
      },
      {
        "index": 43,
        "arxivId": "2502.12118",
        "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
        "score": 3,
        "reason": "Test-time computation efficiency can be related to how well information is represented and accessed."
      },
      {
        "index": 44,
        "arxivId": "2501.19393",
        "title": "s1: Simple test-time scaling",
        "score": 3,
        "reason": "Test-time scaling might benefit from improved input representations or learned task representations."
      },
      {
        "index": 45,
        "arxivId": "2412.05467",
        "title": "The BrowserGym Ecosystem for Web Agent Research",
        "score": 3,
        "reason": "Web agents need to represent web environments and user goals, which is a form of representation learning."
      },
      {
        "index": 46,
        "arxivId": "2410.02052",
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
        "score": 3,
        "reason": "Exploratory learning in agents involves forming representations of the environment to guide exploration."
      },
      {
        "index": 47,
        "arxivId": "2406.08747",
        "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents",
        "score": 3,
        "reason": "Continuous improvement in agents implies adapting their internal representations over time."
      },
      {
        "index": 48,
        "arxivId": "2404.06474",
        "title": "Autonomous Evaluation and Refinement of Digital Agents",
        "score": 3,
        "reason": "Refining agents might involve improving their internal representations based on evaluation feedback."
      },
      {
        "index": 49,
        "arxivId": "2402.17753",
        "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
        "score": 3,
        "reason": "Evaluating long-term memory is directly related to the effectiveness of the underlying representation mechanisms."
      },
      {
        "index": 50,
        "arxivId": "2308.11432",
        "title": "A Survey on Large Language Model based Autonomous Agents",
        "score": 3,
        "reason": "This survey on agents likely touches upon the importance of representation for various agent capabilities, including learning and decision-making."
      },
      {
        "index": 51,
        "arxivId": "2307.13854",
        "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
        "score": 3,
        "reason": "Building autonomous agents for web environments requires them to learn representations of web pages and interactions."
      },
      {
        "index": 52,
        "arxivId": "2306.06070",
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "score": 3,
        "reason": "A generalist web agent needs to learn versatile representations of web structures and user intent."
      },
      {
        "index": 53,
        "arxivId": "2508.06433",
        "title": "Memp: Exploring Agent Procedural Memory",
        "score": 2,
        "reason": "Procedural memory is a type of memory that could benefit from effective representation learning, but it's a specific type of memory."
      },
      {
        "index": 54,
        "arxivId": "2507.21046",
        "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence",
        "score": 2,
        "reason": "Self-evolving agents imply adaptation and learning, which can involve representation learning, but it's a broad topic."
      },
      {
        "index": 55,
        "arxivId": "2506.01952",
        "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
        "score": 2,
        "reason": "Evaluating web browsing agents is related to their performance, which can be influenced by representation learning, but the focus is on evaluation."
      },
      {
        "index": 56,
        "arxivId": "2412.15287",
        "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models",
        "score": 2,
        "reason": "Fine-tuning for sampling might indirectly benefit from better underlying representations, but it's not the primary focus."
      },
      {
        "index": 57,
        "arxivId": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge",
        "score": 2,
        "reason": "LLM-as-a-judge involves evaluating outputs. While representations influence evaluation, this paper's core is the judge paradigm."
      },
      {
        "index": 58,
        "arxivId": "2303.17651",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback",
        "score": 2,
        "reason": "Self-refinement might improve representations implicitly, but the focus is on the refinement process itself."
      },
      {
        "index": 59,
        "arxivId": "2508.12031",
        "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases",
        "score": 1,
        "reason": "Continual relation learning is related to adapting representations, but the focus on 'errors' makes it less direct than other learning papers."
      },
      {
        "index": 60,
        "arxivId": "2504.01990",
        "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
        "score": 1,
        "reason": "Foundation agents are a broad topic; representation learning is a component but not the central theme here."
      },
      {
        "index": 61,
        "arxivId": "2503.07891",
        "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
        "score": 1,
        "reason": "This paper has been listed twice, this is the second instance. Score remains the same."
      },
      {
        "index": 62,
        "arxivId": "2408.09559",
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
        "score": 1,
        "reason": "This paper has been listed twice, this is the second instance. Score remains the same."
      }
    ]
  },
  "verifier": {
    "rank": 1,
    "ranked": [
      {
        "index": 1,
        "arxivId": "2002.05709",
        "title": "A Simple Framework for Contrastive Learning of Visual Representations",
        "score": 7,
        "reason": "Contrastive learning is a foundational technique in representation learning, which is closely related to the target paper's focus on representation learning."
      },
      {
        "index": 2,
        "arxivId": "2503.07891",
        "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
        "score": 7,
        "reason": "This paper directly discusses embeddings and generalizability, aligning with the target's theme of representation learning."
      },
      {
        "index": 3,
        "arxivId": "3",
        "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases",
        "score": 6,
        "reason": "Focuses on learning from errors and continual learning, which can be related to optimizing representations."
      },
      {
        "index": 4,
        "arxivId": "2506.15841",
        "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
        "score": 5,
        "reason": "While focused on agents, 'learning to synergize' and 'efficient' aspects might indirectly relate to representation optimization."
      },
      {
        "index": 5,
        "arxivId": "2504.20595",
        "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
        "score": 5,
        "reason": "Focuses on training for specific tasks, which can involve learning good representations."
      },
      {
        "index": 6,
        "arxivId": "2402.03610",
        "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
        "score": 4,
        "reason": "Retrieval-augmented methods can involve learning effective representations for retrieval."
      },
      {
        "index": 7,
        "arxivId": "2504.09772",
        "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
        "score": 4,
        "reason": "Mentions 'scaling' and 'reasoning', potentially related to improving model performance through better representations."
      },
      {
        "index": 8,
        "arxivId": "2505.22101",
        "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models",
        "score": 4,
        "reason": "Memory augmentation might imply learning representations for efficient memory usage."
      },
      {
        "index": 9,
        "arxivId": "2410.02052",
        "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
        "score": 4,
        "reason": "Exploratory learning can involve developing better representations for exploration."
      },
      {
        "index": 10,
        "arxivId": "2502.12110",
        "title": "A-MEM: Agentic Memory for LLM Agents",
        "score": 4,
        "reason": "Agentic memory might involve learning representations for efficient information storage and retrieval."
      },
      {
        "index": 11,
        "arxivId": "2305.10250",
        "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
        "score": 4,
        "reason": "Long-term memory systems in LLMs often rely on effective representation learning for memory consolidation."
      },
      {
        "index": 12,
        "arxivId": "2404.13501",
        "title": "A Survey on the Memory Mechanism of Large Language Model-based Agents",
        "score": 4,
        "reason": "Surveys on memory mechanisms could discuss underlying representation learning techniques."
      },
      {
        "index": 13,
        "arxivId": "2402.05403",
        "title": "In-Context Principle Learning from Mistakes",
        "score": 3,
        "reason": "Learning from mistakes could lead to better internal representations, though indirectly."
      },
      {
        "index": 14,
        "arxivId": "2409.00872",
        "title": "Self-evolving Agents with reflective and memory-augmented abilities",
        "score": 3,
        "reason": "Self-evolution and memory augmentation could indirectly benefit from improved representations."
      },
      {
        "index": 15,
        "arxivId": "2412.15287",
        "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models",
        "score": 3,
        "reason": "Fine-tuning and sampling might involve learning representations that capture desired inference characteristics."
      },
      {
        "index": 16,
        "arxivId": "2507.21046",
        "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence",
        "score": 3,
        "reason": "Surveys on self-evolving agents might touch upon the importance of adaptable representations."
      },
      {
        "index": 17,
        "arxivId": "2402.17753",
        "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
        "score": 3,
        "reason": "Evaluating memory systems could relate to how well information is represented for recall."
      },
      {
        "index": 18,
        "arxivId": "2507.05257",
        "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions",
        "score": 3,
        "reason": "Similar to the above, evaluating memory efficiency might involve representation quality."
      },
      {
        "index": 19,
        "arxivId": "2507.06229",
        "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
        "score": 3,
        "reason": "Knowledge bases and problem-solving might require learning generalized representations."
      },
      {
        "index": 20,
        "arxivId": "2504.06821",
        "title": "Inducing Programmatic Skills for Agentic Tasks",
        "score": 3,
        "reason": "Inducing skills could involve learning task-specific representations."
      },
      {
        "index": 21,
        "arxivId": "2507.02259",
        "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
        "score": 3,
        "reason": "Reshaping context and memory agents could involve representation learning for efficiency."
      },
      {
        "index": 22,
        "arxivId": "2504.19413",
        "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
        "score": 3,
        "reason": "Scalable long-term memory might rely on compact and effective representations."
      },
      {
        "index": 23,
        "arxivId": "2508.06433",
        "title": "Memp: Exploring Agent Procedural Memory",
        "score": 3,
        "reason": "Procedural memory could be represented and learned efficiently."
      },
      {
        "index": 24,
        "arxivId": "2501.10893",
        "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
        "score": 3,
        "reason": "Learning through interaction and adaptation could involve learning useful representations of the environment."
      },
      {
        "index": 25,
        "arxivId": "2401.13996",
        "title": "Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution",
        "score": 3,
        "reason": "Consolidation and self-evolution might involve learning robust representations."
      },
      {
        "index": 26,
        "arxivId": "2407.09450",
        "title": "Human-inspired Episodic Memory for Infinite Context LLMs",
        "score": 3,
        "reason": "Episodic memory systems often rely on learning representations that capture event details."
      },
      {
        "index": 27,
        "arxivId": "2303.17651",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback",
        "score": 3,
        "reason": "Iterative refinement might implicitly learn better internal representations over time."
      },
      {
        "index": 28,
        "arxivId": "2308.11432",
        "title": "A Survey on Large Language Model based Autonomous Agents",
        "score": 3,
        "reason": "Surveys on agents often discuss foundational aspects like representation learning for decision-making."
      },
      {
        "index": 29,
        "arxivId": "2503.08026",
        "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents",
        "score": 3,
        "reason": "Memory management for dialogue agents might involve learning relevant conversational representations."
      },
      {
        "index": 30,
        "arxivId": "2507.06261",
        "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
        "score": 3,
        "reason": "Advanced capabilities in Gemini might be underpinned by sophisticated representation learning, including for long contexts."
      },
      {
        "index": 31,
        "arxivId": "2508.04700",
        "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
        "score": 3,
        "reason": "Learning from experience for self-evolving agents could involve adapting representations."
      },
      {
        "index": 32,
        "arxivId": "2507.04607",
        "title": "PRIME: Large Language Model Personalization with Cognitive Dual-Memory and Personalized Thought Process",
        "score": 3,
        "reason": "Cognitive dual-memory and thought processes might rely on personalized representations."
      },
      {
        "index": 33,
        "arxivId": "2502.00592",
        "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory",
        "score": 3,
        "reason": "Extending memory capacity often involves learning more efficient representations."
      },
      {
        "index": 34,
        "arxivId": "2306.06070",
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "score": 3,
        "reason": "Generalist agents for the web would benefit from learning versatile representations of web content."
      },
      {
        "index": 35,
        "arxivId": "2506.06698",
        "title": "Contextual Experience Replay for Self-Improvement of Language Agents",
        "score": 3,
        "reason": "Experience replay and self-improvement could involve learning useful representations of past experiences."
      },
      {
        "index": 36,
        "arxivId": "2404.07972",
        "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
        "score": 3,
        "reason": "Benchmarking agents in real environments might require representations that generalize well."
      },
      {
        "index": 37,
        "arxivId": "2404.06474",
        "title": "Autonomous Evaluation and Refinement of Digital Agents",
        "score": 3,
        "reason": "Evaluation and refinement processes could implicitly improve underlying representations."
      },
      {
        "index": 38,
        "arxivId": "2504.01990",
        "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
        "score": 3,
        "reason": "Foundation agents and evolutionary systems might discuss the importance of adaptive representations."
      },
      {
        "index": 39,
        "arxivId": "2306.07863",
        "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
        "score": 3,
        "reason": "Using trajectories as exemplars might involve learning representations of successful action sequences."
      },
      {
        "index": 40,
        "arxivId": "2507.21428",
        "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations",
        "score": 3,
        "reason": "Optimizing memory management for tool calling could involve learning representations of tool usage context."
      },
      {
        "index": 41,
        "arxivId": "2410.10813",
        "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory",
        "score": 3,
        "reason": "Benchmarking long-term memory could involve evaluating the quality of stored representations."
      },
      {
        "index": 42,
        "arxivId": "2509.03646",
        "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning",
        "score": 3,
        "reason": "Hierarchical reasoning might emerge from learning hierarchical representations."
      },
      {
        "index": 43,
        "arxivId": "2406.08747",
        "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents",
        "score": 3,
        "reason": "Benchmarking continuous improvement could indirectly relate to evolving representations."
      },
      {
        "index": 44,
        "arxivId": "2504.13837",
        "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
        "score": 2,
        "reason": "RL's impact on reasoning capacity might be mediated by how it shapes internal representations, but it's indirect."
      },
      {
        "index": 45,
        "arxivId": "2307.12856",
        "title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
        "score": 2,
        "reason": "Long context understanding and program synthesis are tasks that benefit from good representations, but not the primary focus."
      },
      {
        "index": 46,
        "arxivId": "2408.09559",
        "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
        "score": 2,
        "reason": "Hierarchical working memory management could imply learning representations of task states, but the focus is on management."
      },
      {
        "index": 47,
        "arxivId": "2507.21953",
        "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation",
        "score": 2,
        "reason": "Memory augmentation for planning might involve representations of trajectories, but it's task-specific."
      },
      {
        "index": 48,
        "arxivId": "2506.12928",
        "title": "Scaling Test-time Compute for LLM Agents",
        "score": 2,
        "reason": "Scaling test-time compute is more about inference efficiency than representation learning itself."
      },
      {
        "index": 49,
        "arxivId": "2210.03629",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
        "score": 2,
        "reason": "Reasoning and acting are high-level tasks; the underlying representation learning is not the primary focus."
      },
      {
        "index": 50,
        "arxivId": "2307.13854",
        "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
        "score": 2,
        "reason": "Focus is on the environment for agents, not the learning of representations."
      },
      {
        "index": 51,
        "arxivId": "2412.05467",
        "title": "The BrowserGym Ecosystem for Web Agent Research",
        "score": 2,
        "reason": "Similar to WebArena, this focuses on the research environment for agents."
      },
      {
        "index": 52,
        "arxivId": "2308.10144",
        "title": "ExpeL: LLM Agents Are Experiential Learners",
        "score": 2,
        "reason": "Experiential learning by agents could involve representation updates, but it's not the direct focus."
      },
      {
        "index": 53,
        "arxivId": "2506.07976",
        "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
        "score": 2,
        "reason": "Focuses on reasoning strategies and test-time interaction, rather than representation learning."
      },
      {
        "index": 54,
        "arxivId": "2502.14382",
        "title": "S*: Test Time Scaling for Code Generation",
        "score": 1,
        "reason": "Test-time scaling for code generation is a specific application, and representation learning is not the main theme."
      },
      {
        "index": 55,
        "arxivId": "2501.19393",
        "title": "s1: Simple test-time scaling",
        "score": 1,
        "reason": "Focus is on scaling inference, not representation learning."
      },
      {
        "index": 56,
        "arxivId": "2405.15793",
        "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
        "score": 1,
        "reason": "Focus is on automated software engineering using agents, not fundamental representation learning."
      },
      {
        "index": 57,
        "arxivId": "2310.08560",
        "title": "MemGPT: Towards LLMs as Operating Systems",
        "score": 1,
        "reason": "While memory is involved, the 'LLMs as OS' framing is more about system architecture than representation learning."
      },
      {
        "index": 58,
        "arxivId": "2502.12118",
        "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
        "score": 1,
        "reason": "Focus is on the limitations of test-time compute scaling, not representation learning."
      },
      {
        "index": 59,
        "arxivId": "2506.01952",
        "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
        "score": 1,
        "reason": "Evaluation of web browsing agents on specific tasks is not directly related to representation learning."
      },
      {
        "index": 60,
        "arxivId": "2504.00810",
        "title": "Z1: Efficient Test-time Scaling with Code",
        "score": 1,
        "reason": "Focus is on test-time scaling for code generation, not representation learning."
      },
      {
        "index": 61,
        "arxivId": "2409.07429",
        "title": "Agent Workflow Memory",
        "score": 1,
        "reason": "Workflow memory is a specific application of memory, not directly about representation learning principles."
      },
      {
        "index": 62,
        "arxivId": "2411.15594",
        "title": "A Survey on LLM-as-a-Judge",
        "score": 1,
        "reason": "LLM-as-a-judge is about evaluation, not representation learning itself."
      }
    ],
    "metrics": {
      "completeness": 0.9838709677419355,
      "semanticCorrelation": 0.918253117327887,
      "correctness": 1
    },
    "raw": {
      "ranked": [
        {
          "index": 1,
          "arxivId": "2002.05709",
          "title": "A Simple Framework for Contrastive Learning of Visual Representations",
          "score": 7,
          "reason": "Contrastive learning is a foundational technique in representation learning, which is closely related to the target paper's focus on representation learning."
        },
        {
          "index": 2,
          "arxivId": "2503.07891",
          "title": "Gemini Embedding: Generalizable Embeddings from Gemini",
          "score": 7,
          "reason": "This paper directly discusses embeddings and generalizability, aligning with the target's theme of representation learning."
        },
        {
          "index": 3,
          "arxivId": "3",
          "title": "Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases",
          "score": 6,
          "reason": "Focuses on learning from errors and continual learning, which can be related to optimizing representations."
        },
        {
          "index": 4,
          "arxivId": "2506.15841",
          "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
          "score": 5,
          "reason": "While focused on agents, 'learning to synergize' and 'efficient' aspects might indirectly relate to representation optimization."
        },
        {
          "index": 5,
          "arxivId": "2504.20595",
          "title": "ReasonIR: Training Retrievers for Reasoning Tasks",
          "score": 5,
          "reason": "Focuses on training for specific tasks, which can involve learning good representations."
        },
        {
          "index": 6,
          "arxivId": "2402.03610",
          "title": "RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents",
          "score": 4,
          "reason": "Retrieval-augmented methods can involve learning effective representations for retrieval."
        },
        {
          "index": 7,
          "arxivId": "2504.09772",
          "title": "Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning",
          "score": 4,
          "reason": "Mentions 'scaling' and 'reasoning', potentially related to improving model performance through better representations."
        },
        {
          "index": 8,
          "arxivId": "2505.22101",
          "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models",
          "score": 4,
          "reason": "Memory augmentation might imply learning representations for efficient memory usage."
        },
        {
          "index": 9,
          "arxivId": "2410.02052",
          "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
          "score": 4,
          "reason": "Exploratory learning can involve developing better representations for exploration."
        },
        {
          "index": 10,
          "arxivId": "2502.12110",
          "title": "A-MEM: Agentic Memory for LLM Agents",
          "score": 4,
          "reason": "Agentic memory might involve learning representations for efficient information storage and retrieval."
        },
        {
          "index": 11,
          "arxivId": "2305.10250",
          "title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
          "score": 4,
          "reason": "Long-term memory systems in LLMs often rely on effective representation learning for memory consolidation."
        },
        {
          "index": 12,
          "arxivId": "2404.13501",
          "title": "A Survey on the Memory Mechanism of Large Language Model-based Agents",
          "score": 4,
          "reason": "Surveys on memory mechanisms could discuss underlying representation learning techniques."
        },
        {
          "index": 13,
          "arxivId": "2402.05403",
          "title": "In-Context Principle Learning from Mistakes",
          "score": 3,
          "reason": "Learning from mistakes could lead to better internal representations, though indirectly."
        },
        {
          "index": 14,
          "arxivId": "2409.00872",
          "title": "Self-evolving Agents with reflective and memory-augmented abilities",
          "score": 3,
          "reason": "Self-evolution and memory augmentation could indirectly benefit from improved representations."
        },
        {
          "index": 15,
          "arxivId": "2412.15287",
          "title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models",
          "score": 3,
          "reason": "Fine-tuning and sampling might involve learning representations that capture desired inference characteristics."
        },
        {
          "index": 16,
          "arxivId": "2507.21046",
          "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence",
          "score": 3,
          "reason": "Surveys on self-evolving agents might touch upon the importance of adaptable representations."
        },
        {
          "index": 17,
          "arxivId": "2402.17753",
          "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
          "score": 3,
          "reason": "Evaluating memory systems could relate to how well information is represented for recall."
        },
        {
          "index": 18,
          "arxivId": "2507.05257",
          "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions",
          "score": 3,
          "reason": "Similar to the above, evaluating memory efficiency might involve representation quality."
        },
        {
          "index": 19,
          "arxivId": "2507.06229",
          "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving",
          "score": 3,
          "reason": "Knowledge bases and problem-solving might require learning generalized representations."
        },
        {
          "index": 20,
          "arxivId": "2504.06821",
          "title": "Inducing Programmatic Skills for Agentic Tasks",
          "score": 3,
          "reason": "Inducing skills could involve learning task-specific representations."
        },
        {
          "index": 21,
          "arxivId": "2507.02259",
          "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
          "score": 3,
          "reason": "Reshaping context and memory agents could involve representation learning for efficiency."
        },
        {
          "index": 22,
          "arxivId": "2504.19413",
          "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
          "score": 3,
          "reason": "Scalable long-term memory might rely on compact and effective representations."
        },
        {
          "index": 23,
          "arxivId": "2508.06433",
          "title": "Memp: Exploring Agent Procedural Memory",
          "score": 3,
          "reason": "Procedural memory could be represented and learned efficiently."
        },
        {
          "index": 24,
          "arxivId": "2501.10893",
          "title": "Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments",
          "score": 3,
          "reason": "Learning through interaction and adaptation could involve learning useful representations of the environment."
        },
        {
          "index": 25,
          "arxivId": "2401.13996",
          "title": "Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution",
          "score": 3,
          "reason": "Consolidation and self-evolution might involve learning robust representations."
        },
        {
          "index": 26,
          "arxivId": "2407.09450",
          "title": "Human-inspired Episodic Memory for Infinite Context LLMs",
          "score": 3,
          "reason": "Episodic memory systems often rely on learning representations that capture event details."
        },
        {
          "index": 27,
          "arxivId": "2303.17651",
          "title": "Self-Refine: Iterative Refinement with Self-Feedback",
          "score": 3,
          "reason": "Iterative refinement might implicitly learn better internal representations over time."
        },
        {
          "index": 28,
          "arxivId": "2308.11432",
          "title": "A Survey on Large Language Model based Autonomous Agents",
          "score": 3,
          "reason": "Surveys on agents often discuss foundational aspects like representation learning for decision-making."
        },
        {
          "index": 29,
          "arxivId": "2503.08026",
          "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents",
          "score": 3,
          "reason": "Memory management for dialogue agents might involve learning relevant conversational representations."
        },
        {
          "index": 30,
          "arxivId": "2507.06261",
          "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
          "score": 3,
          "reason": "Advanced capabilities in Gemini might be underpinned by sophisticated representation learning, including for long contexts."
        },
        {
          "index": 31,
          "arxivId": "2508.04700",
          "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience",
          "score": 3,
          "reason": "Learning from experience for self-evolving agents could involve adapting representations."
        },
        {
          "index": 32,
          "arxivId": "2507.04607",
          "title": "PRIME: Large Language Model Personalization with Cognitive Dual-Memory and Personalized Thought Process",
          "score": 3,
          "reason": "Cognitive dual-memory and thought processes might rely on personalized representations."
        },
        {
          "index": 33,
          "arxivId": "2502.00592",
          "title": "M+: Extending MemoryLLM with Scalable Long-Term Memory",
          "score": 3,
          "reason": "Extending memory capacity often involves learning more efficient representations."
        },
        {
          "index": 34,
          "arxivId": "2306.06070",
          "title": "Mind2Web: Towards a Generalist Agent for the Web",
          "score": 3,
          "reason": "Generalist agents for the web would benefit from learning versatile representations of web content."
        },
        {
          "index": 35,
          "arxivId": "2506.06698",
          "title": "Contextual Experience Replay for Self-Improvement of Language Agents",
          "score": 3,
          "reason": "Experience replay and self-improvement could involve learning useful representations of past experiences."
        },
        {
          "index": 36,
          "arxivId": "2404.07972",
          "title": "OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments",
          "score": 3,
          "reason": "Benchmarking agents in real environments might require representations that generalize well."
        },
        {
          "index": 37,
          "arxivId": "2404.06474",
          "title": "Autonomous Evaluation and Refinement of Digital Agents",
          "score": 3,
          "reason": "Evaluation and refinement processes could implicitly improve underlying representations."
        },
        {
          "index": 38,
          "arxivId": "2504.01990",
          "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
          "score": 3,
          "reason": "Foundation agents and evolutionary systems might discuss the importance of adaptive representations."
        },
        {
          "index": 39,
          "arxivId": "2306.07863",
          "title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
          "score": 3,
          "reason": "Using trajectories as exemplars might involve learning representations of successful action sequences."
        },
        {
          "index": 40,
          "arxivId": "2507.21428",
          "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations",
          "score": 3,
          "reason": "Optimizing memory management for tool calling could involve learning representations of tool usage context."
        },
        {
          "index": 41,
          "arxivId": "2410.10813",
          "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory",
          "score": 3,
          "reason": "Benchmarking long-term memory could involve evaluating the quality of stored representations."
        },
        {
          "index": 42,
          "arxivId": "2509.03646",
          "title": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning",
          "score": 3,
          "reason": "Hierarchical reasoning might emerge from learning hierarchical representations."
        },
        {
          "index": 43,
          "arxivId": "2406.08747",
          "title": "StreamBench: Towards Benchmarking Continuous Improvement of Language Agents",
          "score": 3,
          "reason": "Benchmarking continuous improvement could indirectly relate to evolving representations."
        },
        {
          "index": 44,
          "arxivId": "2504.13837",
          "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
          "score": 2,
          "reason": "RL's impact on reasoning capacity might be mediated by how it shapes internal representations, but it's indirect."
        },
        {
          "index": 45,
          "arxivId": "2307.12856",
          "title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",
          "score": 2,
          "reason": "Long context understanding and program synthesis are tasks that benefit from good representations, but not the primary focus."
        },
        {
          "index": 46,
          "arxivId": "2408.09559",
          "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model",
          "score": 2,
          "reason": "Hierarchical working memory management could imply learning representations of task states, but the focus is on management."
        },
        {
          "index": 47,
          "arxivId": "2507.21953",
          "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation",
          "score": 2,
          "reason": "Memory augmentation for planning might involve representations of trajectories, but it's task-specific."
        },
        {
          "index": 48,
          "arxivId": "2506.12928",
          "title": "Scaling Test-time Compute for LLM Agents",
          "score": 2,
          "reason": "Scaling test-time compute is more about inference efficiency than representation learning itself."
        },
        {
          "index": 49,
          "arxivId": "2210.03629",
          "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
          "score": 2,
          "reason": "Reasoning and acting are high-level tasks; the underlying representation learning is not the primary focus."
        },
        {
          "index": 50,
          "arxivId": "2307.13854",
          "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
          "score": 2,
          "reason": "Focus is on the environment for agents, not the learning of representations."
        },
        {
          "index": 51,
          "arxivId": "2412.05467",
          "title": "The BrowserGym Ecosystem for Web Agent Research",
          "score": 2,
          "reason": "Similar to WebArena, this focuses on the research environment for agents."
        },
        {
          "index": 52,
          "arxivId": "2308.10144",
          "title": "ExpeL: LLM Agents Are Experiential Learners",
          "score": 2,
          "reason": "Experiential learning by agents could involve representation updates, but it's not the direct focus."
        },
        {
          "index": 53,
          "arxivId": "2506.07976",
          "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
          "score": 2,
          "reason": "Focuses on reasoning strategies and test-time interaction, rather than representation learning."
        },
        {
          "index": 54,
          "arxivId": "2502.14382",
          "title": "S*: Test Time Scaling for Code Generation",
          "score": 1,
          "reason": "Test-time scaling for code generation is a specific application, and representation learning is not the main theme."
        },
        {
          "index": 55,
          "arxivId": "2501.19393",
          "title": "s1: Simple test-time scaling",
          "score": 1,
          "reason": "Focus is on scaling inference, not representation learning."
        },
        {
          "index": 56,
          "arxivId": "2405.15793",
          "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
          "score": 1,
          "reason": "Focus is on automated software engineering using agents, not fundamental representation learning."
        },
        {
          "index": 57,
          "arxivId": "2310.08560",
          "title": "MemGPT: Towards LLMs as Operating Systems",
          "score": 1,
          "reason": "While memory is involved, the 'LLMs as OS' framing is more about system architecture than representation learning."
        },
        {
          "index": 58,
          "arxivId": "2502.12118",
          "title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal",
          "score": 1,
          "reason": "Focus is on the limitations of test-time compute scaling, not representation learning."
        },
        {
          "index": 59,
          "arxivId": "2506.01952",
          "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
          "score": 1,
          "reason": "Evaluation of web browsing agents on specific tasks is not directly related to representation learning."
        },
        {
          "index": 60,
          "arxivId": "2504.00810",
          "title": "Z1: Efficient Test-time Scaling with Code",
          "score": 1,
          "reason": "Focus is on test-time scaling for code generation, not representation learning."
        },
        {
          "index": 61,
          "arxivId": "2409.07429",
          "title": "Agent Workflow Memory",
          "score": 1,
          "reason": "Workflow memory is a specific application of memory, not directly about representation learning principles."
        },
        {
          "index": 62,
          "arxivId": "2411.15594",
          "title": "A Survey on LLM-as-a-Judge",
          "score": 1,
          "reason": "LLM-as-a-judge is about evaluation, not representation learning itself."
        }
      ]
    }
  }
}